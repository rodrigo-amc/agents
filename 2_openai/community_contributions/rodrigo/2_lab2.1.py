import os
from agents import Agent, Runner, OpenAIChatCompletionsModel
import asyncio
from dotenv import load_dotenv
from openai.types.responses import ResponseTextDeltaEvent
from openai import AsyncOpenAI
from zroddeUtils import llmModels


load_dotenv(override=True)
sendgridApiKey = os.getenv("SENDGRID_API_KEY")
openRouterApiKey = os.getenv("OPENROUTER_API_KEY")

# These are three differrent prompts. Each one for a different agent
instructions1 = "You are a sales agent working for ComplAI, \
a company that provides a SaaS tool for ensuring SOC2 \
compliance and preparing for audits, powered by AI. \
You write professional, serious cold emails.\
You just write the email body, without any extra content"

instructions2 = "You are a humorous, engaging sales agent working for ComplAI, \
a company that provides a SaaS tool for ensuring SOC2 compliance and \
preparing for audits, powered by AI. \
You write witty, engaging cold emails that are likely to get a response.\
You just write the email body, without any extra content"

instructions3 = "You are a busy sales agent working for ComplAI, \
a company that provides a SaaS tool for ensuring SOC2 \
compliance and preparing for audits, powered by AI. \
You write concise, to the point cold emails.\
You just write the email body, without any extra content"


# region this is nescessary for work with OpenAI SDK using OpenRouter API
# Create an AsyncOpenAI client with OpenRouter API credentials
asyncOpenAIClient = AsyncOpenAI(
    api_key = openRouterApiKey,
    base_url = "https://openrouter.ai/api/v1"
)

# Create a custom model using OpenRouter
openRouterModel = OpenAIChatCompletionsModel(
    # here you can choose the model that you prefer from OpenRouter
    model = llmModels.free_mistral_Small_31_24B,
    openai_client = asyncOpenAIClient
)
# endregion

sales_agent1 = Agent(
    name = "Profesional Sales Agent",
    instructions = instructions1,
    model = openRouterModel
)

sales_agent2 = Agent(
    name = "Engaging Sales Agent",
    instructions = instructions2,
    model = openRouterModel
)

sales_agent3 = Agent(
    name = "Busy Sales Agent",
    instructions = instructions3,
    model = openRouterModel
)

# region OpenAI Agents SDK - Stream Events Glossary
# Raw Response Events
#    "raw_response_event"              # Raw text chunks from the LLM model
# 
# Run Item Events
#    "message_output_created"          # New message was generated by the agent
#    "handoff_requested"               # Agent requested transfer to another agent  
#    "handoff_occured"                 # Transfer to another agent completed
#    "tool_called"                     # Agent called/executed a tool function
#    "tool_output"                     # Tool function returned output/result
#    "reasoning_item_created"          # Agent created internal reasoning step
#    "mcp_approval_requested"          # MCP (Model Context Protocol) approval needed
#    "mcp_list_tools"                  # MCP requested list of available tools
# 
# Agent Update Events
#    "agent_updated"                   # New agent is now running (after handoff)
# 
# endregion

async def showStreamedEvents(agentInstructions: str) -> None:
    """This function runs the agent with the given instructions and streams the events.
    It prints the "raw_response_event" in the console as they are received."""
    # Run the agent and stream the events
    result = Runner.run_streamed(sales_agent1, input=agentInstructions)
    
    # Iterate over the streamed events
    # and print the raw response events to the console
    async for event in result.stream_events():
        if event.type == "raw_response_event" and isinstance(event.data, ResponseTextDeltaEvent):
            print(event.data.delta, end="", flush=True)

# Example usage of the function
# This will run the agent with the given instructions and print the raw response events to the console
#asyncio.run(showStreamedEvents("Write a cold sales email"))


#region In this example we will use asyncio.gather to run multiple agents concurrently
# then, a fourth agent will collect the results from all three agents and chouse the
# best one based on the instruction passed to the function
async def runAgentsConcurrently(instructions: str) -> list[str]:
    """This function gets a instruction (str) and returns a list of results from the agents."""
    # Run multiple agents concurrently using asyncio.gather
    results = await asyncio.gather(
        Runner.run(sales_agent1, instructions),  # Run the professional sales agent
        Runner.run(sales_agent2, instructions),  # Run the engaging sales agent
        Runner.run(sales_agent3, instructions)   # Run the busy sales agent
    )

    # Extract the final output from each agent's result
    outputs = [result.final_output for result in results]

    # Return the list of outputs from all agents
    return outputs
# endregion


async def generateAndDisplayAgentEmails():
    """Runs the agents concurrently and prints their generated email outputs."""
    instructions = "Write a cold sales email"
    
    # Run the agents concurrently and get their outputs
    outputs = await runAgentsConcurrently(instructions)
    
    # Print the outputs from each agent
    for i, output in enumerate(outputs, start=1):
        print(f"Agent {i} Output:\n{output}\n")
        print("*_" * 40)

# execute the function to generate and display agent emails
#asyncio.run(generateAndDisplayAgentEmails())


# This agent will pick the best email from the three generated by the previous agents
# based on the instruction passed to it.
agent_sales_picker = Agent(
    name = "sales_picker",
    instructions = "You pick the best cold sales email from the given options. \
        Imagine you are a customer and pick the one you are most likely to respond to. \
        Do not give an explanation; replay with the selected email only.",
    model = openRouterModel
)


message = "Write a cold sales email"


async def runSalesPickerAgent(instructions: str) -> str:
    """This function runs the sales picker agent with the given instructions and returns the selected email."""
    # Run the sales picker agent with the provided instructions
    outputs = await runAgentsConcurrently(instructions)
    
    emails = "Cold sales emails:\n\n".join(outputs)

    best = await Runner.run(agent_sales_picker, emails)

    print(f"Best sales email:\n{best.final_output}")


asyncio.run(runSalesPickerAgent(message))





# region Runner.run_streamed() and Runner.run() concepts and differences
# OpenAI SDK Runner Methods - Quick Reference
#
# Two Ways to Run Agents:
#
# 1. Runner.run() - Get Complete Result
#    result = await Runner.run(agent, instructions)
#    final_answer = result.final_output
#    
#    What it does: Runs the agent completely, then gives you the full response when done.
#    Think of it like: Reading an entire file into memory - you get all data at once.
#    Use when: You just want the final answer and don't care about intermediate output.
#
# 2. Runner.run_streamed() - Live Updates  
#    result = Runner.run_streamed(agent, input=instructions)
#    async for event in result.stream_events():
#        if event.type == "raw_response_event":
#            print(event.data.delta, end="")  # Shows text as it's generated
#
#    What it does: Shows you the response as the agent generates it, piece by piece.
#    Think of it like: Reading a file line by line - you process data as it becomes available.
#    Use when: You want to show real-time progress or handle partial responses.
#
# Key Differences:
# - run() returns complete result object → access via result.final_output
# - run_streamed() returns event stream → access via event.data.delta
# - Streaming = processing data incrementally (like iterating through a list)
# - Regular = getting all data upfront (like loading entire array into memory)
# - You can't use final_output with streaming because there's no "final" until stream ends!
#endregion
